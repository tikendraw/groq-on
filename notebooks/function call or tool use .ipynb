{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to demostrate how to use groqon for tool usage or function calling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groqon : [https://www.github.com/tikendraw/groq-on](https://www.github.com/tikendraw/groq-on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to convert dates to years\n",
    "def days_to_years_func(days: int = 0) -> float:\n",
    "    \"\"\"converts days into years\"\"\"\n",
    "    return days / 365\n",
    "\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Evaluate a mathematical expression\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return json.dumps({\"result\": result})\n",
    "    except:  # noqa\n",
    "        return json.dumps({\"error\": \"Invalid expression\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "client2 = Groq(\n",
    "    api_key=\"not needed\",\n",
    "    base_url=\"http://localhost:8080/\",  # match the port used by groqon sever\n",
    "    timeout=30,\n",
    ")\n",
    "MODEL = \"llama3-groq-70b-8192-tool-use-preview\"\n",
    "# MODEL='llama3-8b-8192'\n",
    "# MODEL='llama-3.1-70b-versatile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(user_prompt, client=client2):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "    ]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"calculate\",\n",
    "                \"description\": \"Evaluate a mathematical expression\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The mathematical expression to evaluate\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"days_to_years_func\",\n",
    "                \"description\": \"converts days to years\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"day\": {\n",
    "                            \"type\": \"int\",\n",
    "                            \"description\": \"number of days, e.g. 245\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"days\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        max_tokens=500,\n",
    "        temperature=0.88,\n",
    "        top_p=0.77,\n",
    "        stream=False,\n",
    "    )\n",
    "    print(response)\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        available_functions = {\n",
    "            \"calculate\": calculate,\n",
    "            \"days_to_years_func\": days_to_years_func,\n",
    "        }\n",
    "\n",
    "        messages.append(response_message)\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = str(function_to_call(**function_args))\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "        second_response = client.chat.completions.create(model=MODEL, messages=messages)\n",
    "        print(second_response)\n",
    "        return second_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32m respnse in cnnnectin pool <Response [200] content self.content stream <httpcore._sync.http11.HTTP11ConnectionByteStream object at 0x774874ce6e50>>\u001b[0m\n",
      "\u001b[40m\u001b[31m respnse in cnnnectin pool steam <httpcore._sync.http11.HTTP11ConnectionByteStream object at 0x774874ce6e50>\u001b[0m\n",
      "ChatCompletion(id='chatcmpl-4f79e443-3754-4daf-99e7-b9f017ae8de1', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4n9n', function=Function(arguments='{\"days\": 4312}', name='days_to_years_func'), type='function')]))], created=1722500368, model='llama3-groq-70b-8192-tool-use-preview', object='chat.completion', system_fingerprint='fp_ee4b521143', usage=CompletionUsage(completion_tokens=29, prompt_tokens=309, total_tokens=338, completion_time=0.087751781, prompt_time=0.022203729, queue_time=None, total_time=0.10995551), x_groq={'id': 'req_01j46gbj5dedz8gxw58x8g964p'})\n",
      "\u001b[40m\u001b[32m respnse in cnnnectin pool <Response [200] content self.content stream <httpcore._sync.http11.HTTP11ConnectionByteStream object at 0x77487488cf10>>\u001b[0m\n",
      "\u001b[40m\u001b[31m respnse in cnnnectin pool steam <httpcore._sync.http11.HTTP11ConnectionByteStream object at 0x77487488cf10>\u001b[0m\n",
      "ChatCompletion(id='chatcmpl-f0e25ab1-9198-4e5d-9903-58b68e4e020d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='You have been running for approximately 11.81 years.', role='assistant', function_call=None, tool_calls=None))], created=1722500370, model='llama3-groq-70b-8192-tool-use-preview', object='chat.completion', system_fingerprint='fp_ee4b521143', usage=CompletionUsage(completion_tokens=13, prompt_tokens=111, total_tokens=124, completion_time=0.037759886, prompt_time=0.010123258, queue_time=None, total_time=0.047883144), x_groq={'id': 'req_01j46gbm4hfbnshfkmjrjxmd3h'})\n"
     ]
    }
   ],
   "source": [
    "# user_prompt = \"calculate 3*25-55*2/25-4-2?\"\n",
    "user_prompt = \"i have been running for  4312 days , what would that be in years\"\n",
    "response = run_conversation(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have been running for approximately 11.81 years.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.813698630136987"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_to_years_func(4312)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groqon-A4JUjgUu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
